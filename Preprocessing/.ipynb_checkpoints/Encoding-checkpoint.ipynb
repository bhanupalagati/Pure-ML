{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine:- What can I do I only understand numbers why are giving me a shit of strings\n",
    "# Human:- Hmmmmm give me a moment\n",
    "\n",
    "----------------------  After encoding  ------------------------------\n",
    "# Machine:- Thank you, now I can work again :)\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding\n",
    "Inorder to convert categorical data into contineous data we will depend on encoding\n",
    "There are two types of encoders we can rely on\n",
    "1. OrdinalEncoder\n",
    "2. OneHotEncoder\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinal Encoder\n",
    "\n",
    "This fn will encode data in an increasing order of items. This will create no new columns.\n",
    "\n",
    "Great our data set is simple and algo's are fast.\n",
    "Hold on \"We know ML is nothing but math\"\n",
    "\n",
    "If the encoding is happening in an inceasing order. like 0, 1, 2, 3, 4 for eng, math, science, geography, computers respectively. Machine will give a very high priority for computers than eng.\n",
    "\n",
    "Means we are corrupting our own data.\n",
    "\n",
    "# Let's see a running example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([['male', 'USA', 'Developer'], ['female', 'India', 'Analyst'], ['male', 'China', 'Terrorist']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 2.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinalFit = preprocessing.OrdinalEncoder().fit(data)\n",
    "ordinalData = ordinalFit.transform(data)\n",
    "ordinalData\n",
    "# You can observe value other than 0's & 1's but the columns are same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoder\n",
    "\n",
    "As we know having values like 1, 2, 3, ..... will corrupt the data. Machine thinks \"Bigger the number I have to give more share for that\" But in reality one value is not higher or lower to the other.\n",
    "\n",
    "So, in one hot encoding we will create multiple columns and fills with 1 if that's the value else a 0\n",
    "\n",
    "# Let's see an Eg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 1. 0. 1. 0.]\n",
      " [1. 0. 0. 1. 0. 1. 0. 0.]\n",
      " [0. 1. 1. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "oneHotFit = preprocessing.OneHotEncoder().fit(data)\n",
    "oneHotData = oneHotFit.transform(data)\n",
    "print(oneHotData.toarray())\n",
    "# This is a compressed sparse matrix. We can see that there are 7 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvements\n",
    "\n",
    "<h3> Drop </h3>\n",
    "Reducing a row mean reducing stress on the machine.\n",
    "we cannot go to the ordinalEncoder again.\n",
    "\n",
    "But we can do one thing. If a feature has binary data we don't need to create multiple columns because it will take only 0 or 1\n",
    "\n",
    "\n",
    "<h3> handle_unknown </h3>\n",
    "\n",
    "There is a possibility that you might see a value that's not in training set but in test set. When we transform test set this might create an error.\n",
    "\n",
    "If we make handle_unknown  = \"ignore\" this will create a complete 0 row like [0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'drop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-10ffcc6c52e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#  Previous we have 7 columns now it will become 6 because \"gender\" is a binary column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moneHotFit2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'if_binary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0moneHotData2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moneHotFit2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moneHotData2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'drop'"
     ]
    }
   ],
   "source": [
    "#  Previous we have 7 columns now it will become 6 because \"gender\" is a binary column\n",
    "oneHotFit2 = preprocessing.OneHotEncoder(drop='if_binary').fit(data)\n",
    "oneHotData2 = oneHotFit2.transform(data)\n",
    "print(oneHotData2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "oneHotFit3 = preprocessing.OneHotEncoder(handle_unknown='ignore').fit(data)\n",
    "oneHotData3 = oneHotFit3.transform(np.array([['transgender', 'Africa', 'designer']]))\n",
    "print(oneHotData3.toarray())\n",
    "# we can see all columns as 0's because we used all new values here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas.get_dummies will do the same job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
